# -*- coding: utf-8 -*-
"""3DCNN_91_with_aug.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17mFvK6sTPWKMUlhgCMXuwHaxPWGSz1Y5
"""

!pip install moviepy==1.0.3

from google.colab import drive
drive.mount('/content/drive')

import os
import cv2
import numpy as np
from moviepy.editor import VideoFileClip
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.layers import ConvLSTM2D

def load_and_preprocess_video(video_path, max_frames=25, target_size=(224, 224)):
    """Loads a video, extracts frames, resizes them, and pads/truncates to max_frames."""
    clip = VideoFileClip(video_path)
    frames = []
    for frame in clip.iter_frames():
        # Resize the frame
        resized_frame = cv2.resize(frame, target_size)
        frames.append(resized_frame)

    # Pad or truncate frames to max_frames
    if len(frames) < max_frames:
        padding_frames = max_frames - len(frames)
        last_frame = frames[-1]  # Duplicate the last frame for padding
        frames.extend([last_frame] * padding_frames)
    else:
        frames = frames[:max_frames]  # Truncate if more than max_frames

    frames = np.array(frames)
    # Extract class label from folder structure (two levels up)
    class_label = os.path.basename(os.path.dirname(os.path.dirname(video_path)))
    fps = clip.fps  # Extract frames per second

    return frames, class_label, fps

def load_data(data_folder, classes, max_frames=25, target_size=(224, 224)):
    """Loads data from a folder structure with train and test subfolders."""
    X_train = []
    y_train = []
    X_test = []
    y_test = []

    for class_name in classes:
        for split in ['train', 'test']:
            split_folder = os.path.join(data_folder, class_name, split)
            for video_file in os.listdir(split_folder):
                if video_file.endswith('.mp4'):
                    video_path = os.path.join(split_folder, video_file)
                    frames, label, fps = load_and_preprocess_video(video_path, max_frames, target_size)
                    if split == 'train':
                        X_train.append(frames)
                        y_train.append(label)
                    else:
                        X_test.append(frames)
                        y_test.append(label)

    # Convert labels to numerical values (if needed)
    label_encoder = LabelEncoder()
    y_train = label_encoder.fit_transform(y_train)
    y_test = label_encoder.transform(y_test)

    # Reshape data for 3D CNN
    def reshape_and_normalize(data):
        num_frames = data[0].shape[0]
        frame_height = data[0].shape[1]
        frame_width = data[0].shape[2]
        data = np.array(data)
        data = data.reshape(data.shape[0], num_frames, frame_height, frame_width, 3)
        data = data / 255.0  # Normalize pixel values
        return data

    X_train = reshape_and_normalize(X_train)
    X_test = reshape_and_normalize(X_test)

    return X_train, X_test, y_train, y_test

# Data Augmentation: Horizontally flip all training frames
X_train = np.array([np.array([np.fliplr(frame) for frame in video]) for video in X_train])

# --- Data Loading ---
video_folder = '/content/drive/MyDrive/cow/data'  # Replace with your video folder path
classes = ['healthy', 'sick']  # Replace with your class names

X_train, X_test, y_train, y_test = load_data(video_folder, classes)

# Assuming all videos have the same number of frames, height, and width
num_frames = X_train[0].shape[0]
frame_height = X_train[0].shape[1]
frame_width = X_train[0].shape[2]

# Data Augmentation: Horizontally flip all training frames
X_train = np.array([np.array([np.fliplr(frame) for frame in video]) for video in X_train])

# Calculate the total number of frames in each split
num_train_frames = X_train.shape[0] * X_train.shape[1]  # Multiply num_samples * num_frames_per_sample
num_test_frames = X_test.shape[0] * X_test.shape[1]

print(f"Total number of train frames: {num_train_frames}")
print(f"Total number of test frames: {num_test_frames}")

import matplotlib.pyplot as plt
import numpy as np

# Assume X_train is your 5D array
num_samples = X_train.shape[0]
num_frames = X_train.shape[1]

# Select a range of frames to visualize
start_frame = 0
end_frame = 5

# Create subplots for each frame
fig, axes = plt.subplots(1, end_frame - start_frame + 1, figsize=(15, 5))

# Loop through the selected frames and display them
for i, frame_index in enumerate(range(start_frame, end_frame + 1)):
    frame = X_train[0][frame_index] # Select a frame from the first video
    axes[i].imshow(frame)
    axes[i].set_title(f"Frame {frame_index}")
    axes[i].axis("off")

plt.show()

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

def create_3d_cnn_model(input_shape, num_classes):
    model = keras.Sequential([
        # Input Layer
        layers.Input(shape=input_shape),

        # Convolutional Layer 1
        layers.Conv3D(32, (3, 3, 3), activation='relu', padding='same'),

        # Max Pooling Layer 1
        layers.MaxPooling3D((2, 2, 2)),

        # Convolutional Layer 2
        layers.Conv3D(64, (3, 3, 3), activation='relu', padding='same'),

        # Max Pooling Layer 2
        layers.MaxPooling3D((2, 2, 2)),

        # Flatten Layer
        layers.Flatten(),

        # Fully Connected Layer 1
        layers.Dense(128, activation='relu'),

        # Dropout Layer
        layers.Dropout(0.5),

        # Fully Connected Layer 2 (Added)
        layers.Dense(64, activation='relu'),

        # Dropout Layer (Added)
        layers.Dropout(0.5),  # Adjust dropout rate as needed

        # Output Layer
        layers.Dense(1, activation='sigmoid')
    ])
    return model



# Adapt for cattle classification:
input_shape = (25, 224, 224, 3)  # Assuming 35 frames per video
num_classes = len(classes)  # Replace 'classes' with your list of cattle classes
model = create_3d_cnn_model(input_shape, num_classes)

# Compile the model:
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Use class weights for handling class imbalance (modified)
history = model.fit(X_train, y_train,
                    epochs=50,  # Adjust as needed
                    batch_size=16)  # Pass class weights here

# Data Augmentation: Horizontally flip all training frames
X_train = np.array([np.array([np.fliplr(frame) for frame in video]) for video in X_train])

# --- 5. Evaluate the Model ---

loss, accuracy = model.evaluate(X_test, y_test)
print(f"Test Loss: {loss:.4f}")
print(f"Test Accuracy: {accuracy:.4f}")

from sklearn.metrics import confusion_matrix, classification_report

# --- Generate predictions ---
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)  # Convert predictions to class labels

# --- Classification Matrix ---
cm = confusion_matrix(y_test, y_pred_classes)
print("Classification Matrix:")
print(cm)

# --- Classification Report ---
cr = classification_report(y_test, y_pred_classes, target_names=classes)
print("Classification Report:")
print(cr)
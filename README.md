This study proposes a spatiotemporal deep learning framework for automated cattle lameness detection using publicly available video data. We curate and publicly release a balanced set of 50 online video clips featuring 42 individual cattle, recorded from multiple viewpoints in both indoor and outdoor environments.  The videos were categorized into lame and nonlame classes based on visual gait characteristics and metadata descriptions. After applying data augmentation techniques to enhance generalization, two deep learning architectures were trained and evaluated: 3D Convolutional Neural Networks (3D CNN) and Convolutional Long-Short-Term Memory (ConvLSTM2D). The 3D CNN achieved a video-level classification accuracy of 90\%, with a precision, recall, and F1 score of 90. 9\% each, outperforming the ConvLSTM2D model, which achieved 85\% accuracy. Unlike conventional approaches that rely on multistage pipelines involving object detection and pose estimation, this study demonstrates the effectiveness of a direct end-to-end video classification approach. 
Compared with the best end-to-end prior method (C3D-ConvLSTM, 90. 3\%), our model achieves comparable accuracy while eliminating pose estimation preprocessing.
